
# Decision rules for vaccine safety surveillance  

In vaccine safety surveillance, the main observations of interest are medical diagnoses used as proxies for the biological condition of interest (adverse event). Gradually accumulating diagnoses form the sample to be analyzed and decisions related to safety signal generation are made based on the sample. The goal is to stop observing and take some further action if an unexpectedly high number of adverse events have been observed. Dynamically determing what exactly is "unexpectedly high" is a problem that this chapter aims to solve.  

One of the key elements of a safety surveillance method is a decision rule for generating safety signals. The available sample never perfectly represents the total study population of interest, which can be thought to include also unborn individuals, possibly experiencing adverse events in the future. Furthermore, there is random variation in the occurrence of adverse events in the population. The decision making process in safety surveillance involves uncertainty and inevitably some amount of error is expected.  

A desirable quality of a safety surveillance method is to control the expected rate of false positive and false negative signals. When a true association between a vaccination and an adverse event exists, another desirable quality is to generate the signal as soon as possible. In other words, a natural goal is to minimize the number of adverse events needed to generate the signal, given some fixed rates of false positive and false negative signals.

This chapter discusses sequential hypothesis testing, which is a statistical method that can be utilized for vaccine safety surveillance. Sequential hypothesis testing provides the means to both control the expected rates of false positive and false negative safety signals, as well as to minimize the expected time to signal generation.  

## Hypothesis tests in vaccine safety surveillance

Statistical hypothesis testing is a method of statistical inference for decision making under uncertainty. Uncertainty usually arises from the fact that available observations do not cover the whole population of interest, but rather are a sample from that population. In a regular hypothesis testing scenario, there is a single fixed sample and a single hypothesis test is performed to reach a conclusion. The setting in safety surveillance is different, since observations arrive sequentially.

In the following sections, I will discuss the use of hypothesis testing for deriving decision rules for safety signal generation. I will first describe hypothesis testing in general and then discuss testing with sequential observations. 

### Statistical hypotheses 

Statistical inference is based on  on a family of probability models $P(Y | \boldsymbol\theta)$ for the observations $Y$, indexed by the parameters $\boldsymbol\theta$. A statistical hypothesis is a proposition which assigns restrictions for the parameter of the statistical model. Usually there are two hypotheses: the null hypothesis $H_0$ and the alternative hypothesis $H_1$. These are expressed by   

$$H_0 : \boldsymbol\theta \in \Theta_0 \quad H_1 : \boldsymbol\theta \in \Theta_1,$$


where $\Theta_0$ and $\Theta_1$ are disjoint and usually $\Theta_0 \cup \Theta_1 = \Theta$, so that the two hypothesis together cover the whole parameter space (all possible values of the parameter). For short I will denote $\boldsymbol\theta \in \Theta_0$ as $\boldsymbol\theta_0$ and similarily for $\boldsymbol\theta_1$.  

A hypothesis is called simple if it addresses only a single point in the parameter space. It is common that the null hypothesis is simple, i.e. $H_0: \theta = \theta_0$. In many applications such as in vaccine safety, the most interesting alternative hypothesis is of the form $H_1 : \theta > \theta_0$. This type of hypothesis -- which addresses more than a single point in the parameter space -- is called a composite hypothesis.  

When the objective is to find evidence of an association between an exposure and an event (for example that the rate ratio for exposed and not exposed is positive), the null proposition (hypothesis) is a state of no association. The alternative hypothesis is composite: some positive association. Using the rate ratio parameter $RR$, this can be stated as two competing hypotheses as follows:

\begin{equation} \label{eq:hypotheses}
H_0: RR = 1 \quad H_1: RR > 1
\end{equation}


### Hypothesis testing

In statistical hypothesis testing, two statistical models $P(\mathbf{Y} \mid \boldsymbol\theta_0)$ and $P(\mathbf{Y} \mid \boldsymbol\theta_1)$, defined by the competing hypotheses $H_0$ and $H_1$, are compared. Usually the comparison is done by defining a test statistic $T = T(\mathbf{y})$ for which high values are critical to the null hypothesis and the probability distribution of $T$ is known under $H_0$. If the observed value for $T$ is very unlikely when $H_0$ were true, then one chooses to reject $H_0$.

The test statistic can be, for example, the likelihood ratio:

\begin{equation}
\label{eq:LR}
LR 
= \frac{L(\boldsymbol\theta_1 ; \mathbf y)}{L(\boldsymbol\theta_0 ; \mathbf y)} 
= \frac{P(\mathbf{y} \mid \boldsymbol\theta_1)}{P(\mathbf{y} \mid \boldsymbol\theta_0)}.
\end{equation}

Any value of the likelihood ratio greater than 1 means that the observations are more likely under the alternative hypothesis ($P(\mathbf{y} \mid \boldsymbol\theta_1) > P(\mathbf{y} \mid \boldsymbol\theta_0)$).

### Errors and power  

When a decision is made between two competing hypothesis, two types of errors can be made:  

- Type I error: $H_1$ is chosen ($H_0$ rejected) when the $H_0$ is true.
- Type II error: $H_0$ is chosen ($H_0$ accepted) when the $H_1$ is true.  

The probabilities of type I and II errors are usually denoted by $\alpha$ and $\beta$, respectively. Terminology related to hypothesis testing is displayed in Table 3.1.  

The complement of $\beta$ is called the power of the hypothesis test: the probability of choosing $H_1$ (rejecting $H_0$) when $H_1$ is true. If the hypotheses are as in (\ref{eq:hypotheses}) and the parameter of interest is $RR$, the power of a hypothesis test is usually a function of $RR$, meaning that higher values of $RR$ make it more likely for the test to reject the null hypothesis. This also means that the actual type II error rate is a decreasing function of $RR$. 

In the context of vaccine safety surveillance the above means that one would be more likely to conclude that there is a difference in the rate of events between two groups, the bigger that difference is. This is of course a positive observation and a desirable quality. But it is also important because it leads to the following: knowing the type II error rate or the power of a test before collecting observations is impossible without knowledge of the actual $RR$.  

\begin{table}[h]
\label{tab:hypothesis-terminology}
\caption{Terminology related to statistical hypothesis testing} \vspace{5mm}
\begin{tabular}{ l  l }
\hline 
Term  & Description \\ [1.5mm]
\hline \\ [-3mm]
$H_0$ & The null hypothesis ($H_0 : \boldsymbol\theta \in \Theta_0$) \\ [1.5mm]
$H_1$ & The alternative hypothesis ($H_1 : \boldsymbol\theta \in \Theta_1$) \\ [1.5mm]
Composite hypothesis & A hypothesis which adresses more than a single point in the parameter space. \\ 
 & For example $H_1: \theta > 1$ \\ [1.5mm]
$\alpha$ & $P(\text{reject } H_0 \mid H_0)$. The type I error rate (false positive rate) \\ [1.5mm]
$\beta$ &  $P(\text{accept } H_0 \mid H_1)$. The type II error rate (false negative rate) \\ [1.5mm]
Power & $1 - \beta$ \\ [1.5mm]
\hline
\end{tabular}
\end{table}


## Sequential analysis

From a statistical inference point of view, a situtation where observations accumulate gradually is different from a more common situation with a fixed number of observations. With a fixed bumber of observations, one can perform a single statistical hypothesis test and make a single decision. With accumulating data, multiple such tests can be done. Sequential analysis focuses on situations where there is a need to perform an analysis whenever new observations arrive. Sequential hypothesis tests can be used to derive decision rules for each new observation.

A naive approach to sequential analysis would be to perform a standard hypothesis test on the accumulating data set each time new observations become available. Hypothesis testing is based on the general idea that if observations are unlikely under a statistical model defined by $H_0$, then some assumptions of that model can be questioned. However, if an experiment is repeated multiple times, then even very unlikely outcomes of the experiment are more likely to be observed during at least one of the trials. Repeated analysis of accumulating data creates a problem, since repetition introduces multiple chances to reject the $H_0$. The naive approach needs adjustment: in a situation of accumulating data, methods designed specifically for sequential analysis are needed.  

Sequential analysis, developed by @Wald1945 during the second world war, adresses the problem of hypothesis testing in a situation where observations arrive sequentially. Wald defined a sequential test of a statistical hypothesis as a test procedure which gives a rule of making one of three possible decisions at a single trial of the experiment:

1. Accept the null hypothesis.
2. Reject the null hypothesis.
3. Continue the experiment by making an additional observation.

@Wald1945 developed the sequential probability ratio test (SPRT), which is the optimal sequential hypothesis test between two simple hypotheses [@Wald1948].

SPRT has since been extended to adress composite hypotheses with so called sequential generalized probability ratio tests. @Kulldorff2011 introduced a version of such a test, called the maxSPRT, designed for vaccine safety surveillance. I will now briefly introduce SPRT and then describe in detail the maxSPRT and its self-controlled binomial variant BmaxSPRT.

### Sequential probability ratio test: SPRT \label{section:SPRT}

Wald's [-@Wald1945] sequential probability ratio test (SPRT) is a sequential hypothesis test designed for testing two simple hypotheses. SPRT is based on the likelihood ratio:

\begin{equation}
\label{eq:LR-SPRT}
LR_n 
= \frac{L(\boldsymbol\theta_1 ; \mathbf{y}_n)}{ L(\boldsymbol\theta_0 ; \mathbf{y}_n)}
= \frac{P(\mathbf y_n \mid \boldsymbol\theta_1) }{ P(\mathbf y_n \mid \boldsymbol\theta_0)  }
,
\end{equation}

where $\mathbf{y}_n$ are the current observations for $n = 1, 2,  ...$ The SPRT procedure is described in Algorithm \ref{section:SPRT}. Even though there is no defined upper limit to the number of observations, @Wald1945 [p. 128] proved that the SPRT experiment will eventually terminate with probability 1. @Wald1948 also showed that SPRT is the optimal sequential test for testing a simple null hypothesis against a simple alternative, in the sense that it has the lowest expected sample size among tests of equal power. 

\begin{tcolorbox}[enlarge top by=0.5cm, colback=white,title=Algorithm \ref{section:SPRT}: SPRT] 
Input: Desired Type I and Type II error rates $\alpha$ and $\beta$, test statistic function $LR_n$ as in (\ref{eq:LR-SPRT}) \\
1. Compute critical upper and lower boundaries $A = (1- \beta)/ \alpha$ and $B = (1 - \alpha) / \beta$. \\
2. After observation n = 1, 2, ... do  \\
- if $LR_n \geq A$ stop, reject $H_0$ \\
- if $LR_n \leq B$ stop, reject $H_1$ \\
- otherwise draw an additional observation.
\end{tcolorbox}  

### Critical values of SPRT  

The SPRT test has two critical regions: $Q_0 = \{LR_n \mid LR_n \geq A, B < LR_{n-1} < A\}$ for rejecting $H_0$ and $Q_1 = \{LR_n \mid LR_n \leq B, B < LR_{n-1} < A\}$ for rejecting $H_1$ (accepting $H_0$), defined by the two critical values $A$ and $B$. These regions define the stopping criteria for the test for all observations $n = 1, 2, ...$. The probability $\alpha$ of rejecting the null hypothesis when it is true (type I error) is given by $P(Q_0 \mid H_0)$ and the probability $\beta$ of rejecting the alternative hypothesis when it is true (type II error) is given by $P(Q_1 \mid H_1)$. The SPRT procedure and the critical regions are illustrated in Figure \ref{fig:SPRT}.

The critical values $A$ and $B$ should be chosen to match desired (low) error rates (probabilities). In order to determine the values $A$ and $B$, Wald considered the entire sample space consisting of all possible realisations in the sequential test. He showed that $A$ and $B$ can be approximated by functions of the desired $\alpha$ and $\beta$ regardless of the statistical model by setting $A = (1- \beta)/ \alpha$ and $B = (1 - \alpha) / \beta$. He also remarked that this procedure will guarantee that the actual type I and II errors will not exceed $\alpha$ and $\beta$ and will only differ from them slightly [@Wald1945, 127-133].  


```{r, fig.align ="center", fig.height = 4.5, fig.width = 10, fig.cap = "\\label{fig:SPRT}A graphical illustration of the critical boundaries of the sequential probability ratio test (SPRT) where the test statistic is the likelihood ratio (LR). If the numerator of LR is the likelihood according to the alternative hypothesis, then high values of LR mean that the alternative model fits the data better and are thus critical to the null hypothesis. The upper limit A (dashed red line) then defines the critical region for the null hypothesis. Similarily, the lower limit B (dashed green line) defines the critical region for the alternative hypothesis."}
op <- par(pin = c(4,2.5), cex = 1.2, mar = c(4,4,4,2))
set.seed(666)
n <- 100
y <- numeric(n) + 1
for(i in 1:(n-1)) y[i + 1] <- y[i]*1.015 + rnorm(1, sd = 0.1)
plot(y, type = "l", ylim = c(0, 7), ylab = "LR(n)", main = "SPRT illustration", xlab = "sample size n", axes = F)
axis(1, lab = F);axis(2, lab = F)
abline(h = 0.5, col = "green", lty = 2)
abline(h = 3, col = "red", lty = 3)
legend("topright", legend = c("upper limit (A)", "test statistic",  "lower limit (B)"), col = c("red","black", "green"), bty = "n", lty = c(3, 1, 2))
par(op)
```

### SPRT and a composite alternative hypothesis

SPRT was designed for testing two simple hypotheses. Wald did, however, propose a solution to deal with composite alternative hypotheses. In this section I will introduce this solution and then illustrate a weakness related to it.

@Wald1945 [p. 158] remarked that in common statistical models the power of the SPRT test is an increasing function of the parameter of interest $\theta$. He therefore suggested dealing with a composite alternative hypothesis by simply defining a value $\theta_1$ such that the difference $\theta_1 - \theta_0$ would be of significant interest in the application and then setting a point alternative hypothesis $H_1 : \theta = \theta_1$. Then one could simply utilize SPRT as described in algorithm \ref{section:SPRT} and test a simple null hypothesis against a simple alternative.  

When the parameter of interest is the rate ratio, one example of the strategy above would be to view rate ratios $1 \leq RR < 1.2$ as of no interest and therefore, for example, set $H_1: RR = 1.2$. @Kulldorff2011 remarked that an unfortunate relation between the choice of $RR_1$ and the actual (i.e. true) $RR_a$ can either 

1. delay the rejection of $H_0$ when the actual rate of events is higher than the rate suggested by $H_1$ (delayed signal generation)
2. increase the type II error when the actual rate of events is closer to the rate suggested by $H_0$ than the rate suggested by $H_1$ (decreased power).  

In other words, scenario (1) can happen when $RR_0 < RR_1 << RR_a$ and scenario (2) when $RR_0 < RR_a << RR_1$.  

The intuition leading to (1) is that if $RR_a$ is far from both $RR_0$ and $RR_1$, then both models, defined by $H_0$ and $H_1$, are inappropriate and therefore $P(\mathbf{y} \mid RR_1)$ and $P(\mathbf{y} \mid RR_0)$ will on average be close to each other. For example, if one specifies $RR_0 = 1$ and $RR_1 = 1.2$ when in reality $RR_a = 6$, then both $H_0$ and $H_1$ specify inappropriate models. In such a case the high number of adverse events expected to be observed would be given low probability by both models, as illustrated in the left panel of Figure \ref{fig:SPRT-weakness}.

In the example described above the two likelihoods would remain close to each other and the likelihood ratio would remain close to one. It might take a large number of samples to reach a point where $LR \geq A$ and $H_0$ is rejected. This is clearly undesirable especially with serious adverse events, where it is desirable that an unexpectedly high number of adverse events would lead to a quick decision to reject $H_0$.  

To see the intuition behind scenario (2), assume again that we are interested to find if $RR > 1$. Following Wald's suggestion one might for example choose $RR_0 = 1$ and $RR_1 = 2$, when $RR_a = 1.4$. In this case the model specified by $H_0$ is closer to the real value of $RR$ and it is thus expected that $P(\mathbf{y} \mid RR_0)  > P(\mathbf{y} \mid RR_1)$, making it more likely that $LR \leq B$ ($H_1$ rejected). Thus the type II error is increased. See the right panel of Figure \ref{fig:SPRT-weakness} for an illustration.

```{r, fig.width = 8, fig.height = 4, fig.cap = "\\label{fig:SPRT-weakness}A graphical illustration of a weakness of Wald's SPRT. The blue line describes the actual relative incidence rate (RR_a) and the green and red lines describe the likelihood under the null and alternative hypotheses, respectively. Left: A choice of point alternative hypothesis (RR_1) close to the rate specified by the null hypothesis (RR_0) and far from RR_a can delay the rejection of H0, because a high relative rate is given low likelihood under both hypotheses. Right: A choice of point alternative hypothesis that is 'too agressive' compared to the actual relative rate can increase the type II error rate, because the null hypothesis gives higher likelihood to the actual relative rate."}
op <- par(no.readonly = T)
cols = c("green", "red", "blue")

# tick <- function(pos, label, color) {
#   abline(v = pos, col =color, lty = 2)
#   axis(1, at = pos, col = color, label = label)
# }

layout(matrix(c(1,1,2,3), ncol=2, byrow=TRUE), heights=c(1, 4))

# common legend
par(mai=c(0,0,0,0))
plot.new()
legend("center", inset = 0, legend = c("L(RR_0)", "L(RR_1)"), col = cols[1:2], lty = 1, horiz = TRUE, xpd = T)

par(las = 1, mar = c(5, 1, 4, 2))
# poor H1 can delay detection
RR0 <- 1; RR1 <- 3; act <- 7
curve(dnorm(x, RR0, 1), yaxt = "n", xaxt = "n", ylim = c(0, 0.6), xlim = c(-3, 10), col = "green", lty = 1, xlab = "", ylab = "")
curve(dnorm(x, RR1, 1), yaxt = "n", xaxt = "n", ylim = c(0, 0.6), xlim = c(-3, 10), col = "red", lty = 1, xlab = "", ylab = "", add = T)
axis(1, c(RR0,act), col = c("black", cols[3]), label = c("1", "RR_a"))
abline(v = c(RR0, act), col = c("black", cols[3]), lty = 2)

title(sub = "Poor H1 can delay signal generation", main = expression(atop("Both models are 'bad'","L(RR_1)" %~~% "L(RR_0)")))

# poor H1 can increase type II error rate
RR0 <- 1; RR1 <- 7; act <- 3
curve(dnorm(x, RR0, 1), yaxt = "n", xaxt = "n", ylim = c(0, 0.6), xlim = c(-3, 10), col = "green", lty = 1, xlab = "", ylab = "")
curve(dnorm(x, RR1, 1), yaxt = "n", xaxt = "n", ylim = c(0, 0.6), xlim = c(-3, 10), col = "red", lty = 1, xlab = "", ylab = "", add = T)
axis(1, c(RR0,act), col = c("black", cols[3]), label = c("1", "RR_a"))
abline(v = c(RR0, act), col = c("black", cols[3]), lty = 2)

title(sub = "Poor H1 can increase Type II error rate", main = expression(atop("The H0 model is 'better'","L(RR_1) < L(RR_0)")))

par(op)
```


### Maximized sequential probability ratio test: maxSPRT \label{section:maxSPRT}

A solution suggested by @Kulldorff2011 to remove the weakness of SPRT as described above is to modify the test in two ways: 

1. Maximize the likelihood ratio in the space of the alternative hypotheses $\Theta_1$.
2. Instead of setting a lower bound $B$ to reject $H_1$, define a maximum number of observations $N$ and reject $H_1$ if $n \geq N$.

The modified sequential test is called the maximized sequential probability ratio test (maxSPRT). The maxSPRT is a general sequential hypothesis testing method, which can be used on any statistical model.  

@Kulldorff2011 introduced two versions of the maxSPRT method: one based on Poisson likelihood and the other on binomial likelihood. The binomial model arises when the study design is a simple self-controlled design such as the simple SCCS introduced in section \ref{section:simpleSCCS}.  

When the parameter of interest is the rate ratio $RR$, the maxSPRT test statistic is 

\begin{equation}\label{eq:LR-maxSPRT}
LR_n = \underset{RR_1}{max} \frac{ L(RR_1; \mathbf y_n) }{ L(RR_0; \mathbf y_n) } = \underset{RR_1}{max} \frac{P( \mathbf y_n \mid RR_1)}{P( \mathbf y_n \mid RR_0)}.
\end{equation}  

The maxSPRT procedure is described in Algorithm \ref{section:maxSPRT}. The procedure uses a test statistic such as (\ref{eq:LR-maxSPRT}) and requires that the desired type I error rate and the maximum number of observations are chosen before the experiment is carried out. 

\begin{tcolorbox}[enlarge top by=0.5cm, colback=white,title=Algorithm \ref{section:maxSPRT}: MaxSPRT]\label{alg:maxSPRT}
Input: Desired type I error rate $\alpha'$, upper boundary for the sample size $N$, test statistic function $LR_n$ as in (\ref{eq:LR-maxSPRT})\\
1. Compute the critical value $c$ of the test.\\
2. After observation $n = 1, .., N - 1$ do\\
- if $LR_n \geq c$ stop, reject $H_0$ \\
- otherwise continue\\
3. After observation $N$ do\\
- if $LR_N \geq c$ stop, reject $H_0$\\
- otherwise reject $H_1$
\end{tcolorbox}

### Critical values of maxSPRT

The values of the test statistic (\ref{eq:LR-maxSPRT}) are easy to compute. What then remains is the definition of the critical region of the test: which values of the test statistic should lead to the decision of rejecting the null hypothesis. Since higher values of the test statistic are always more critical to the $H_0$, it is sufficient to determine a single critical value, which defines the boundary of the critical region.  

The first step of the maxSPRT procedure -- as described in Algorithm \ref{alg:maxSPRT} -- is to compute the critical value $c$ corresponding to the desired type I error $\alpha'$. Values of (\ref{eq:LR-maxSPRT}) higher than $c$ then lead to rejection of $H_0$. The critical region of maxSPRT thus is 

\begin{equation}
\label{eq:maxSPRT-critical-region}
Q_c = \{LR_n \mid LR_n \geq c, LR_{n-1} < c\}, \quad \text{for all} \quad n = 1, 2, ..., N.
\end{equation}

The actual type I error of the test is given by $P(Q_c \mid H_0)$. If this probability can be computed, then $c$ can be found iteratively. The computation of $P(Q_c \mid H_0)$ depends on the statistical model for the observations (i.e. the likelihood function). @Kulldorff2011 [pp. 65-67, p. 72] describe how to determine $c$ for the Binomial and Poisson likelihoods. In what follows I will present the binomial case in detail, where a Markov chain probability model can be utilized to determine $c$.

## Binomial maxSPRT: BmaxSPRT

Let us now adopt the maxSPRT method in the setting of the simple SCCS. Assume that for the sequence of observations $(y_n, n), n = 0, 1, ...N$, where $y_n$ denotes the number of "cases" out of $n$ events, the probability distribution for $y_n$ is given by the binomial distribution as described in section \ref{section:simpleSCCS}. The probability of "success" (i.e. adverse event classified as a "case"), depends on the unknown rate ratio parameter $RR$ and the known ratio between the lengths of the control and risk periods, $z$.  

Let the two hypotheses be as in (\ref{eq:hypotheses}). Using equation (\ref{eq:LR-maxSPRT}), the maxSPRT test statistic is given by

\begin{equation}\label{eq:LR-BmaxSPRT}
LR_n
= \underset{RR>1}{max} \frac{  P(y_n \mid RR) }{  P(y_n \mid RR = 1) }
= \underset{RR>1}{max} \frac{ (\frac{RR}{z + RR})^{y_n} (\frac{z}{z + RR})^{n - y_n} }{ (\frac{1}{z + 1})^{y_n} (\frac{z}{z + 1})^{n - y_n}  }.
\end{equation}

@Kulldorff2011 call a sequential test based on the test statistics (\ref{eq:LR-BmaxSPRT}) the binomial maxSPRT (BmaxSPRT). A simple SCCS design combined with the maxSPRT method is one way to arrive at the BmaxSPRT, which shows that the BmaxSPRT method is self-controlled.

Computation of (\ref{eq:LR-BmaxSPRT}) requires maximization. It is easy to see that maximization in terms of $RR$ depends only on the numerator, which is a likelihood function. Maximizing a likelihood function is a common task in statistics and the value that maximizes the likelihood in terms of the parameter $RR$ is called the maximum likelihood estimate (MLE) for $RR$, denoted by $\hat{RR}$.  

For computational reasons, it is usually convenient to operate with the log likelihood ratio instead. Since the logarithm is a strictly increasing function, maximizing the log likelihood ratio is equivalent to maximizing the likelihood ratio. The (log) likelihood ratio is maximized by finding the MLE for $RR$, which is easily seen to be $(y_n \cdot z) / (n - y_n)$. Since we are not interested in situations where $RR < 1$, one should use $\hat{RR} = max\{1, \frac{z \cdot y_n}{n - y_n} \}$. Then the test statistic becomes

\begin{equation}\label{eq:LLR-BmaxSPRT}
LLR_n = log(LR_n) 
= log \left( \frac{ (\frac{\hat{RR}}{z + \hat{RR}})^{y_n} \cdot (\frac{z}{z + \hat{RR}})^{n - y_n} }{ (\frac{1}{z + 1})^{y_n} \cdot (\frac{z}{z + 1})^{n - y_n} } \right).
\end{equation}

A simplified form of (\ref{eq:LLR-BmaxSPRT}) is given by @Kulldorff2011 [p. 71]. The BmaxSPRT experiment proceeds as described in Algorithm \ref{alg:maxSPRT}, utilizing the test statistic (\ref{eq:LLR-BmaxSPRT}). 


### BmaxSPRT as a Markov chain \label{section:computing-BmaxSPRT-critical}

In the discrete binomial case, the critical value $c$ of the maxSPRT procedure can be found iteratively by utilizing a Markov chain probability model to compute the type I error probability $P(Q_c \mid H_0)$. In what follows I will formulate BmaxSPRT as a Markov chain by defining the state space and transition probabilities of the experiment. 

#### State space

In the BmaxSPRT sequential test, the possible states of the experiment comprise all possible combinations of "trials" ($n$) and "successes" ($y_n$) during the experiment, bounded by the maximum number of observations $N$. Therefore the state space $S$ is defined as follows:

\begin{equation}
\label{def:state-space}
S = (n, y_n) , \quad \text{where} \quad n = 0, 1, ..., N \quad \text{and} \quad y_n = 0, 1, .. , n.
\end{equation}

The experiment always starts at state $(0,0)$. Clearly, there is a finite number of states. In fact, there are $M = \sum_{n = 0}^{N} (n + 1) = (N+1) (N+2) /2$ possible states.  

#### Transitions and critical region

In the BmaxSPRT experiment, adverse events are sequentially classified as a "case" ("success", $Y = 1$) or a "control" ("failure", $Y = 0$), depending on the outcome of a Bernoulli random variable $Y$ (see Section \ref{section:simpleSCCS}). Possible transitions in the state space $S$ are therefore as follows:  

\begin{equation}\label{eq:transitions}
\begin{split}
"success": (n, y_n) \rightarrow (n + 1, y_n + 1) \\
"failure": (n, y_n) \rightarrow (n + 1, y_n).
\end{split}
\end{equation}

If the experiment is stopped at some state $s \in S$, then that state is called absorbing: it is impossible to leave the state. Otherwise, a state is called transient. The states for which $n = N$ are absorbing because the maximum number of observations has been reached. Also, the states for which the value of the test statistic (\ref{eq:LLR-BmaxSPRT}) reaches the critical value $c$, are absorbing. 

Let $LLR(s)$ denote the value of the test statistic (\ref{eq:LLR-BmaxSPRT}) for state $s \in S$. The critical region of the test can then be defined as follows:

\begin{equation}\label{eq:absorbing}
Q = \{s \in S \mid LLR(s) \geq c\}.
\end{equation}

It should be noted that by this definition $Q$ may contain states which are impossible to reach (because of previous absorbing states). For example, $Q$ could contain the (absorbing) states $(n = 4,y_n = 4)$ and $(n = 5, y_n = 5)$. Now $(5,5)$ can not be reached since the only possible transition to $(5,5)$ is from $(4,4)$ and $(4,4)$ is absorbing. However, this does not cause theoretical or practical problems.

\begin{figure}[h]
\caption{Visualization of a BmaxSPRT type Markov Chain. The chain starts from the node (0,0) and a trial with the result "success" or "failure" is performed at each node, with p being the probability for "success". In this example the state (3,3) with 3 successes out of 3 trials is an absorbing state.}
\includegraphics[]{figures/markov}
\end{figure}


#### Transition probabilities 

The BmaxSPRT experiment starts at the state $(0,0)$ with probability 1. Therefore, a vector of probabilities for the initial state is given by 

\begin{equation}\label{eq:markov-initial}
\underset{1 \times M}{\mathbf{v}} = (1, 0, ..., 0).
\end{equation}

A Bernoulli random variable $Y$ determines the transitions. The transition probabilities for the transient states, i.e., for those for which $LLR(n, y_n) < c, n \leq N$, are given by:

\begin{equation}\label{eq:transition-probabilities1}
\begin{split}
P \{ (n+1,y_{n+1}) \mid (n,y_n) \} = P(Y=1) = p \\
P \{ (n+1,y_{n}) \mid (n,y_n) \} = P(Y=0) = 1 - p
\end{split}
\end{equation}

where $p$ is as in (\ref{eq:p}). Under the null hypothesis ($RR = 1$) $p = 1 / (1 + z)$. The probabilities of other transitions from the transient states are zero. The transition probabilities for the absorbing states, i.e., for which $LLR(n, y_n) \geq c$ or $n = N$, are:

\begin{equation}\label{eq:transition-probabilities2}
P \{ (n,y_{n}) \mid (n,y_n) \} = 1,
\end{equation}

meaning that if such a state is reached, it is never left. These transition probabilities show that the BmaxSPRT experiment has the Markov property: the transition probabilities only depend on whether the previous state was absorbing or not.

The transition probabilities are gathered in the transition matrix $\mathbf{P}$, which defines the probability distribution over all the transitions from state to state in the state space $S$. Each row and column of $\mathbf{P}$ corresponds to one of the states $s \in S$ and $\mathbf{P}_{ij}$ gives the probability of the transition from $s_i$ to $s_j$. The size of $\mathbf{P}$ depends on $N$ and the values of $\mathbf{P}$ depend on the values of $p$ and $c$, of which $c$ defines the absorbing states.

\begin{figure}
\label{eq:transition-matrix}
\bordermatrix{
&      (0,0) & (1,0) & (1,1) & (2,0) & (2,1) & (2,2) & (3,0) & (3,1) & .. & (N,0) & .. & (N,N) \cr
(0,0) &  0   & 1-p   & p     & 0     & 0     & 0     & 0     & 0     & .. & 0     & .. & 0     \cr
(1,0) &  0   & 0     & 0     & 1-p   & p     & 0     & 0     & 0     & .. & 0     & .. & 0     \cr
(1,1) &  0   & 0     & 0     & 0     & 1-p   & p     & 0     & 0     & .. & 0     & .. & 0     \cr
(2,0) &  0   & 0     & 0     & 0     & 0     & 0     & 1-p   & p     & .. & 0     & .. & 0     \cr
(2,1) &  0   & 0     & 0     & 0     & 0     & 0     & 0     & 1-p   & .. & 0     & .. & 0     \cr
(2,2) &  0   & 0     & 0     & 0     & 0     & 1     & 0     & 0     & .. & 0     & .. & 0     \cr
(3,0) &  0   & 0     & 0     & 0     & 0     & 0     & 0     & 0     & .. & 0     & .. & 0     \cr
(3,1) &  0   & 0     & 0     & 0     & 0     & 0     & 0     & 0     & .. & 0     & .. & 0     \cr
.     &  .   & .     & .     & .     & .     & .     & .     & .     & .. & .     & .. & .     \cr
.     &  .   & .     & .     & .     & .     & .     & .     & .     & .. & .     & .. & .     \cr
(N,0) &  0   & 0     & 0     & 0     & 0     & 0     & 0     & 0     & .. & 1     & .. & 0     \cr
.     &  .   & .     & .     & .     & .     & .     & .     & .     & .. & .     & .. & .     \cr
.     &  .   & .     & .     & .     & .     & .     & .     & .     & .. & .     & .. & .     \cr
(N,N) &  0   & 0     & 0     & 0     & 0     & 0     & 0     & 0     & .. & 0     & .. & 1     \cr
}
\caption{
An example of a transition matrix describing the transition probabilities between the states in the BmaxSPRT experiment. The rows and columns of the matrix correspond to the possible states and $\mathbf{P}_{ij}$ gives the probability of the transition $s_i \rightarrow s_j$. For example under the null hypothesis the probability of the transition $(0,0) \rightarrow (1,0)$ ("failure") is given by $1-p = z / (1 + z)$ and the probability of the transition $(0,0) \rightarrow (1,1)$ ("success") is given by $p = 1 / (1 + z)$. In this example the state $(2,2)$ is an absorbing state and a transition can happen only onto itself. The states where the maximum number of observations is reached are all absorbing states.
}
\end{figure}

The probabilities of being in each of the states after $N$ transitions in the state space are given by

\begin{equation}\label{eq:state-probabilities}
\underset{1 \times M}{\mathbf{p}} = \mathbf{v} \mathbf{P}^{(N)}.
\end{equation}


### Type I error 

The critical value $c$ of the BmaxSPRT experiment defines the states in the critical region $Q$ which then defines the type I error $\alpha$. To compute the value of $\alpha$ for a given $c$, the overall probability of reaching the critical region can be computed by summing over the probabilities of being in each of the states $s \in Q$ after $N$ transitions in the state space $S$. Using the result introduced in (\ref{eq:state-probabilities}), the type I error probability for any BmaxSPRT critical region $Q$ is given by 

\begin{equation}
\label{eq:probability-critical}
\alpha_{(BmaxSPRT)} = P(Q \mid H_0) = \sum_{s \in Q} \mathbf{v}\mathbf{P}_0^{(N)},
\end{equation}

where $\mathbf{P}_0$ is the transition matrix, where $p = 1 / (1 + z)$ is according to $H_0$.


### Critical values \label{section:BmaxSPRT-critical}

Any critical value candidate $c'$ defines the states in the critical region $Q$, corresponding to some type I error $\alpha$. For a desired type I error $\alpha'$, the goal is to find a $c$ such that $P(Q \mid H_0) \approx \alpha'$, meaning that the overall probability of rejecting the null hypothesis when it is true is (at least approximately) $\alpha'$. Utilizing equation (\ref{eq:probability-critical}), it is possible to try out possible values $c'$ until the $c$ is found which best matches the desired $\alpha'$. One way to execute this procedure is given in algorithm \ref{section:BmaxSPRT-critical}.  

It should be noted that for a desired $\alpha'$, the algorithm finds the value $c$ which corresponds to a type I error $\alpha$ for which the inequality $\alpha \leq \alpha'$ holds. It is unlikely that $\alpha = \alpha'$ exactly. This is due to the discrete nature of the binomial distribution.  

\begin{tcolorbox}[enlarge top by=0.5cm, colback=white,title=Algorithm \ref{section:BmaxSPRT-critical}: BmaxSPRT critical]
Input: States $S$, initial probabilities $\mathbf{v}$, transition matrix $\mathbf{P_0}$, test statistic function $LLR_n$ as in (\ref{eq:LLR-BmaxSPRT}) \\
1. Compute all possible test statistic values $L = \{LLR(s) \mid s \in S\}$ and sort $L$ from lowest to highest. \\
2. Choose $c' = min\{L\}$ to be the critical value. The absorbing states are  $Q' = \{s \in S \mid LLR(s) \geq c' \}$. \\
3. Compute $P(Q' \mid H_0) = \pi$ \\
- if $\pi \leq \alpha'$, stop, choose $c'$ to be the critical value $c$ for the type I error rate $\pi = \alpha$ \\
- otherwise remove $c'$ from $L$ and go to 2.
\end{tcolorbox}

### Power

The power of the BmaxSPRT experiment depends on the true value of the rate ratio. When the true rate ratio is $RR_a$, the probability of an event classified as a "case" is given by $p_a = RR_a / (RR_a + z)$. The true transition matrix of the experiment $\mathbf{P}_a$ is then defined by these probabilities.  

From this observation it is easy to see that the power of the BmaxSPRT experiment can be computed for any chosen fixed value of $RR$, say $RR_1 = 1.5$. One simply needs to define the transition matrix $\mathbf{P}_1$, where the probabilities are given by $p_1 = RR_1 / (RR_1 + z)$. This value only corresponds to the actual power of the experiment in the case where $RR_1 = RR_a$, which is of course unlikely. However, this procedure can provide a conservative estimate for the power of the experiment for a reasonable (small) choice of fixed $RR_1$.

Denoting the critical region corresponding to a desired $\alpha'$ as $Q_0$, the power of the BmaxSPRT experiment is given by the overall probability of reaching the critical region:  

\begin{equation}\label{eq:BmaxSPRT-power}
\text{Power}_{(BmaxSPRT)} = P(Q_0 | H_1) = \sum_{s \in Q_0} \mathbf{v}\mathbf{P}_1^{(N)},
\end{equation}

where $\mathbf{v}$ are the initial probabilities of the states given in equation (\ref{eq:markov-initial}) and $\mathbf{P}_1$ is the transition matrix, where $p = RR_1 / (RR_1 + z)$ for some fixed choice of $RR_1$.


## Grouped observations \label{section:group-sequential}

The sequential hypothesis testing methods discussed so far (SPRT, maxSPRT, BmaxSPRT) assume that the value of the test statistic is evaluated whenever a new observation (a medical diagnosis) arrives. This applies to situations where data are available in near real time and observations arrive individually. This type of analysis is called continuous sequential analysis. Continuous sequential analysis is applicaple in situtations where the adverse events of interest are reasonably rare and medical diagnoses are collected reasonably often (for example daily).  

Due to administrative reasons, sometimes medical diagnoses become available for analysis in groups. For example, the National Health and Welfare Institute (Finland) receives data from the HILMO register three times a year (2016). Unless the adverse events of interest are extremely rare, it can be expected that more than a single observation becomes available at the same time. The methods applicable in these situations are called group sequential methods [@Silva2015]. 

According to @Silva2015 group sequential and continuous sequential analyses can be formally defined as follows. These definitions are given here only to aid discussion and in an effort to distinguish between group sequential and continuous sequential analyses. 

*Let $X_t$ be a non-negative integer valued stochastic process describing the number of adverse events that occur during a $[0, t]$ time window.*

\begin{definition}[Group sequential analysis]
\label{def:group-sequential}
For a set of constants $A_1, ..., A_K$ and a sequence of $\{ t_i\}^K_{i=1}$ of times, a group sequential analysis design is any procedure that rejects the null hypothesis if $X_{t_i} \geq A_i$ for some $i \in \{1, ..., K\}$  
\end{definition}

\begin{definition}[Continuous sequential analysis]
\label{def:continuous-sequential}
For a function $B(t)$, a continuous sequential analysis design is any procedure that rejects the null hypothesis if $X_t \geq B(t)$ for some $0 < t \leq L$.  
\end{definition}

In the coming sections I will discuss why the grouped nature of the data should affect a sequential hypothesis test and its critical values. I will then discuss possible solutions. 

### Adjusting for grouped observations  

@Silva2015 discuss the differences between group sequential and continuous sequential analyses. I will present a short overview of that discussion. I will show that the following statements are true.  

1. Continuous sequential analysis should not be used if data become available in groups.
2. Any post-market safety surveillance system should attempt to obtain data as frequently as possible.

To see the intuition for statement 1, assume a special case of group sequential analysis with only a single group of observations. The two choices are then to either perform a retrospective continuous sequential analysis or do a single hypothesis test (using the single group of data). Assume that the same test statistic is used in both cases. For the continuous sequential analysis, the critical value of the test statistic must adjust for multiple chances to reject the $H_0$. This means that it must be more difficult to reject the $H_0$ when $H_1$ is true. Continuous sequential analysis would therefore always have lower power than group sequential analysis if a group of data are already available. 

The reason for statement 2 is that a continuous sequential method is always superior to a group sequential method if observations can be made separately. To see the intuition for this, assume a group sequential design that rejects $H_0$ when the total number of events (after a group of observations) is at least $y_c$. Now assume a continuous sequential design that checks the observations separately and rejects $H_0$ as soon as there are $y_c$ events. The error rates of the two designs are identical because the number of events is non-decreasing (both designs reject $H_0$ *iff* at some point there are $y_c$ events). However, the continuous method is superior because it can reject the $H_0$ sooner (with a smaller sample size). Therefore for every group sequential design there is a superior continuous sequential design.  

A conclusion can be made that not adjusting for the availability of the data can result in either loss of power or an increase in the expected sample size. Analyses should always be performed as soon as possible, using all the available data.

### Group sequential methods

The same statistical model and test statistic that would be utilized in a continuous sequential analysis can be applied in group sequential analysis. However, when analyses are done for groups of data, there are less opportunities to reject the $H_0$ and, therefore, for a given critical value the type I error of a group sequential analysis is smaller. The critical values should then be chosen differently. Unfortunately, if the number of observations per group is unkown, the computation of the critical values becomes difficult. Two assumptions could be made to simplify this computation, but the validity of the assumptions is questionable.

The problem of determining the critical values of a group sequential test would simplify if the number of
observations per group were assumed to be fixed (fixed group sizes). @R-Sequential have implemented this solution for computing critical values of a group sequential BmaxSPRT test in their Sequential R package, available in the Comprehensive R Archive Network (CRAN). This assumption makes the problem very similar to the situation discussed in section \ref{section:computing-BmaxSPRT-critical}. The intution for the similarity is that continuous BmaxSPRT can be seen as a special case of a group sequential hypothesis test with group sizes fixed at 1.  

It is quite obvious that if adverse events are assumed to arrive as a random process in time but are collected during infrequent time intervals, the number of observations per group is by assumption a random variable. Therefore the solution of fixed group sizes does not seem satisfactory if the grouped nature of the data were due to administrative reasons.  

The problem would also simplify if the maximum number of groups was fixed. However, assuming that the group sizes are unkown, fixing the number of groups will not fix the number of observations at the end of surveillance. Remember that the goal of safety surveillance is to keep collecting and analyzing data until there is sufficient information regarding a possible association between the exposure and the event. Naturally, the amount of information depends on the amount of observations. Therefore, it would clearly be better to fix the number of observations than the number of groups.

A possible solution which needs neither simplifying assumption is to use an error spending approach, as described by @Jennison1999 in their book focusing on group sequential methods in clinical trials. Next, I will introduce the concept of error spending functions and maximum information trials, which could be useful approaches for future research regarding vaccine safety surveillance with grouped observations.    

### Error spending 

One solution to group sequential analysis for random group sizes is to use an error spending approach (also known as alpha spending) [@Jennison1999, ch. 7]. The idea of error spending is that for $K$ groups, the type I error $\alpha$ is partioned into probabilities $\pi_1, ..., \pi_K$ which sum to $\alpha$. For the test statistics $Z_k$, critical values $c_k$ are calculated so that

\begin{equation}
P(|Z_1| < c_1, ..., |Z_{k-1}| < c_{k-1}, |Z_k| \geq c_k) = \pi_k
\end{equation}

Intuitively this means that for each group $k$, only a proportion of the desired error probability $\alpha$ is spent. A practical problem remaining is: how should each $\pi_k$ be chosen? To solve this problem, @Jennison1999 [pp. 148-150] introduce families of error spending functions and compare their properties.  

An error spending function is a non-decreasing function which partitions the desired type I error rate $\alpha$ and for which $f(0) = 0$ and $f(t) = \alpha$ for $t \geq 1$. In the paradigm of maximum information trials (discussed next), the value $f(t)$ indicates the cumulative type I error to be spent when a fraction $t$ of the maximum anticipated information $I_{max}$ has been obtained. @Jennison1999 [p. 148] suggest a family of error spending functions defined by

\begin{equation} \label{eq:error-spending-func}
f(t) = min\{\alpha \cdot t^p, \alpha \}
\end{equation}

where the choices of $p \in \{1,3\}$ yield similar results to more classical approaches suggested by @Pocock1977 and @OBrien1979, which belong to the Wang & Tsiatis family of error spending functions.  

### Maximum information trials \label{section:infotrials}

Utilizing the concept of error spending, @Jennison1999 [pp. 146-148] discuss decision rules in the case of two-sided alternative hypotheses, where the stopping rule for accepting $H_0$ is defined by a target maximum information level, denoted by $I_{max}$. The information level for group $k$ is defined as

\begin{equation} \label{eq:information-level}
I_k = \{var(\hat\theta^{(k)})^{-1}\}, k = 1, 2, ..
\end{equation}

where $\hat\theta$ is the estimator for the parameter of interest $\theta$. A maximum information trial uses an error spending function $f(t)$ as described earlier. The type I errors allocated to each analyses are

\begin{equation}
\begin{split}
\pi_1 = f(I_1 / I_{max}) \\
\pi_k = f(I_k / I_{max}) - f(I_{k-1} / I_{max}).
\end{split}
\end{equation}

A decision rule for a maximum information trial is described in Algorithm \ref{section:infotrials} [@Jennison1999, p. 54]. 

\begin{tcolorbox}[enlarge top by=0.5cm, colback=white,title=Algorithm \ref{section:infotrials}: A maximum information trial]
Input: target information $I_{max}$, sequence of groups $k$, test statistic function $Z$. \\
1. Define $K$ as the smallest value $k$ for which the information reaches the target information: $K = min\{k \mid I_k \geq I_{max} \}$ \\
\\
2. After group $k = 1, ... , K-1$ \\
- if $|Z_k| \geq c_k$ stop, reject $H_0$ \\
- otherwise continue to group k + 1 \\

3. After group $K$ \\
- if $|Z_k| \geq c_k$ stop, reject $H_0$ \\
- otherwise stop, accept $H_0$
\end{tcolorbox}

The target information $I_{max}$ is a similar idea to the maximum sample size in maxSPRT in that it too defines a boundary related to the sample size after which the experiment ends and $H_0$ is accepted. In their example utilizing the maximum information trial approach, @Jennison1999 [pp. 150-153] assume that the test statistic has a normal distribution and the alternative hypothesis is two-sided. In maxSPRT type surveillance, the alternative hypothesis is one-sided and the test statistic is not assumed to be normal.  

Maximum information trials provide a promising approach for grouped observations in vaccine safety surveillance, but further research is needed to adopt the method in the maxSPRT setting.  